Of course. Here is a detailed MVP specification for "Argos," designed to be fed directly into an AI coding assistant like Cursor. It is highly explicit, architected for extensibility, and includes considerations for responsive design.

MVP Specification: Argos - A Visual Argumentation Co-Pilot
I. Project Overview & Core Philosophy

Project Name: Argos

Core Concept: A web-based "Centaur" tool for visual thinking and argumentation. The user provides strategic direction and evaluation, while an LLM co-pilot provides speed, brainstorming, and structural assistance.

MVP Goal: To build a functional prototype that proves the core interaction loop: A user creates a claim, and the AI can be prompted to generate supporting or refuting claims, which are instantly visualized on a 2D canvas. The application must be architected for future expansion.

II. Technology Stack

Frontend Framework: React with TypeScript.

Visualization Library: React Flow - chosen for its component-based nature, extensibility, and built-in controls.

Backend Framework: Node.js with Express.js and TypeScript.

LLM Integration: OpenAI Node.js SDK.

Styling: Tailwind CSS for rapid, responsive UI development.

State Management (Frontend): Zustand - for its simplicity and minimal boilerplate.

Local Persistence: Browser localStorage for saving and loading the graph state (no database or user auth in MVP).

III. System Architecture

The system consists of three main parts:

React Frontend: A single-page application that renders the argument graph using React Flow. It manages the UI state and communicates with the backend via a REST API.

Node.js/Express Backend: A simple API server with one primary endpoint (/api/generate). It receives requests from the frontend, formats prompts, and communicates with the LLM service.

LLM Service: A dedicated module on the backend that handles all interactions with the OpenAI API, including prompt engineering and error handling.

This separation ensures the frontend is purely for presentation and the backend handles all business logic and external service calls.

IV. Data Models (TypeScript Interfaces)

Define these in a shared types.ts file for both frontend and backend use if possible.

Generated typescript
// types.ts

export interface ArgumentNode {
  id: string; // Unique ID, can be generated by a library like nanoid
  type: 'argumentNode'; // Custom node type for React Flow
  position: { x: number; y: number }; // Position on the canvas
  data: {
    label: string; // The text content of the claim
    author: 'user' | 'llm';
  };
}

export interface ArgumentEdge {
  id: string;
  source: string; // ID of the source ArgumentNode
  target: string; // ID of the target ArgumentNode
  type: 'argumentEdge'; // Custom edge type
  data: {
    relation: 'supports' | 'refutes' | 'unpacks';
  };
  animated: boolean; // Makes the edge "flow"
}

V. Frontend Implementation Details

File Structure:

Generated code
src/
├── components/
│   ├── ArgumentCanvas.tsx
│   ├── ArgumentNode.tsx
│   ├── InteractionPanel.tsx
├── services/
│   └── api.ts
├── store/
│   └── useStore.ts  // Zustand store
└── App.tsx
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
IGNORE_WHEN_COPYING_END

1. Zustand Store (store/useStore.ts)

Manages the state of nodes and edges.

Provides actions: addNode, addEdge, updateNodeLabel, setNodes, setEdges.

Includes logic to save the graph to localStorage on any change and load from it on initial render.

2. Main Component (App.tsx)

Renders the ArgumentCanvas component.

Contains a top-level button: "Add Initial Claim". Clicking this adds a new root ArgumentNode to the canvas.

3. Canvas Component (components/ArgumentCanvas.tsx)

Uses the ReactFlowProvider and the main ReactFlow component.

Fetches nodes and edges from the Zustand store.

Defines nodeTypes and edgeTypes to point to our custom components.

Handles React Flow events like onNodesChange, onEdgesChange.

Renders the InteractionPanel when a node is selected.

4. Custom Node Component (components/ArgumentNode.tsx)

Receives node data as props.

Renders a div with styling (e.g., rounded corners, box-shadow, background color based on data.author).

Contains a textarea that becomes editable on double-click, updating the node's label in the Zustand store.

Displays a colored border when selected.

Includes Source and Target handles from React Flow to allow connections.

5. Interaction Panel (components/InteractionPanel.tsx)

Appears next to the currently selected node.

Props: selectedNode: ArgumentNode.

Content: Three buttons:
* [+] Support: Green button (bg-green-500).
* [–] Refute: Red button (bg-red-500).
* [?] Unpack: Blue button (bg-blue-500).

Functionality: On-click, each button calls the API service (services/api.ts) with the selected node's ID, text, and the corresponding action ('supports', 'refutes', 'unpacks'). While waiting for the API response, it should show a loading state (e.g., disable buttons, show a spinner).

6. API Service (services/api.ts)

Exports an async function: generateAndAddNode(sourceNode: ArgumentNode, action: 'supports' | 'refutes' | 'unpacks').

This function:
1. Calls the backend POST /api/generate endpoint with the required payload.
2. On success, receives the new node and edge data.
3. Calls the addNode and addEdge actions from the Zustand store to update the UI.

7. Responsive Design

Desktop: The canvas takes up the majority of the screen. Controls are clearly visible.

Mobile: The InteractionPanel should appear above or below the selected node, not to the side. Button sizes should be larger for touch targets. The "Add Initial Claim" button should be prominent. Use Tailwind's responsive prefixes (e.g., md:flex-row) to adjust layouts.

VI. Backend API Implementation Details

File Structure:

Generated code
server/
├── src/
│   ├── services/
│   │   └── llmService.ts
│   ├── controllers/
│   │   └── argumentController.ts
│   └── index.ts
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
IGNORE_WHEN_COPYING_END

1. Main Server File (index.ts)

Initializes the Express app.

Sets up middleware (CORS, body-parser).

Defines the route: app.post('/api/generate', argumentController.handleGenerate).

Starts the server.

2. Controller (controllers/argumentController.ts)

Defines the handleGenerate async function.

Logic:
1. Validate the request body ({ sourceNode, action }).
2. Call the llmService.generateArgument(sourceNode.data.label, action).
3. On success, construct a new ArgumentNode and ArgumentEdge object.

Generate new unique IDs for the node and edge.

Position the new node intelligently (e.g., below the source node).
4. Send a 200 OK response with { newNode, newEdge } as the JSON payload.
5. Implement robust error handling, sending a 500 status with an error message if the LLM call fails.

VII. LLM Service & Prompt Engineering

File: services/llmService.ts

This service abstracts the OpenAI API call.

Generated typescript
// services/llmService.ts
import OpenAI from 'openai';

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

type Action = 'supports' | 'refutes' | 'unpacks';

function getPromptTemplate(action: Action, claim: string): string {
  const baseInstruction = "You are a clear and concise reasoning assistant. Given a claim, generate a *single, concise* new claim as a response. Do not add any preamble or explanation. Just provide the text of the new claim.";

  switch (action) {
    case 'supports':
      return `${baseInstruction}\n\nHere is the claim to support:\n"${claim}"\n\nYour concise supporting claim:`;
    case 'refutes':
      return `${baseInstruction}\n\nHere is the claim to refute:\n"${claim}"\n\nYour concise refuting claim:`;
    case 'unpacks':
      return `${baseInstruction}\n\nHere is the claim to analyze:\n"${claim}"\n\nIdentify and state a key underlying assumption of this claim:`;
  }
}

export async function generateArgument(claim: string, action: Action): Promise<string> {
  const prompt = getPromptTemplate(action, claim);

  const response = await openai.chat.completions.create({
    model: 'gpt-3.5-turbo', // Use a fast and cheap model for the MVP
    messages: [{ role: 'user', content: prompt }],
    temperature: 0.7,
    max_tokens: 50, // Keep responses short and snappy
  });

  return response.choices[0].message.content.trim();
}
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
TypeScript
IGNORE_WHEN_COPYING_END

This spec provides a clear, step-by-step guide for an AI assistant to generate the foundational code for Argos, with a strong emphasis on a clean, extensible, and responsive architecture.